# -*- coding: utf-8 -*-
"""research

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12UPDhnCfZ4g3cuT2qj00B6WPkmY_Fkkp
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture --no-stderr
# %pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python wikipedia google-generativeai google-genai langchain_google_genai

import os
import getpass
import dotenv
from datetime import datetime, timedelta
dotenv.load_dotenv()
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY")

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro-latest",  # ✅ or any other from model list
    temperature=0.7  # You can adjust this
)

res= llm.invoke("test")
res.content

res= llm.invoke("True if the user's question requires external search like browser to answer, False otherwise. : what is pervious question i asked ")
res.content

from typing import List
from typing_extensions import TypedDict
from langgraph.graph import START, MessagesState, StateGraph
from pydantic import BaseModel, Field
import operator
from typing import Annotated



class SearchDecision(BaseModel):
    needs_search: bool = Field(
        description="True if the user's question requires external search to answer, False otherwise."
    )

class Researchstate(MessagesState):
  question:str
  answer:str
  context: Annotated[list, operator.add]
  needs_search: bool

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.messages import AIMessage
search_classifier_prompt = [
    SystemMessage(content="""
You are a smart stock research agent helper.

Your job is to determine whether a user's stock-related question needs external search for live market data.

If the question asks about:
- Current stock prices, market cap, or financial metrics
- Recent earnings, news, or market events
- Stock analysis, performance, or comparisons
- Market trends, sectors, or economic indicators
- Any real-time stock market information

→ Return: `needs_search = true`

If the question is about:
- Previous conversation (e.g. "What stock did I just ask about?")
- Greetings or small talk (e.g. "hello", "thanks")
- General investment concepts already discussed
- Clarification of previous recommendations

→ Return: `needs_search = false`

Remember: For stock information, we almost always need fresh, live data from external sources.
""")
]


def check(state):
  question = state["question"]
  decision_model = llm.with_structured_output(SearchDecision)
  decision = decision_model.invoke(search_classifier_prompt + [HumanMessage(content=question)])
  return {"needs_search": decision.needs_search,
          "messages": state["messages"]
}

import os
os.environ["TAVILY_API_KEY"] = "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"

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.document_loaders import WikipediaLoader
tavily_search = TavilySearchResults(max_results=3)

def search_web(state):
  """retrives docs from web search """
  tavily_search=TavilySearchResults(max_results=6)
  now = datetime.now()
  three_days_ago = now - timedelta(days=3)
    
  now_str = now.strftime('%Y-%m-%d %H:%M')
  past_str = three_days_ago.strftime('%Y-%m-%d %H:%M')
  original_question = state["question"]
  enhanced_query = (
        f"{original_question} updates, prices, or news from {past_str} to {now_str}, "
        f"latest market activity, recent performance past 72 hours"
    )
  print(enhanced_query)
  search_docs= tavily_search.invoke(enhanced_query)
  




  formatted_search_docs = "\n\n---\n\n".join(
        [
            f'<Document href="{doc["url"]}">\n{doc["content"]}\n\n**SOURCE URL: {doc["url"]}**\n</Document>'
            for doc in search_docs
        ]
    )
  return {"context":[formatted_search_docs]}

def search_wiki(state):
  """retrives docs from wiki search """
  search_docs= WikipediaLoader( query= state["question"],load_max_docs=6).load()
  formatted_search_docs = "\n\n---\n\n".join(
        [
            f'<Document source="{doc.metadata["source"]}" page="{doc.metadata.get("page", "")}">\n{doc.page_content}\n\n**SOURCE URL: {doc.metadata["source"]}**\n</Document>'
            for doc in search_docs
        ]
    )
  return {"context":[formatted_search_docs]}

def generate_ans(state):
  """node to answer a question """
  context= state["context"]
  question= state["question"]
  needs_search= state["needs_search"]
  messages = state.get("messages", [])

  # Initialize variables for streaming
  full_response = ""

  if needs_search:
    print("📈 Fetching live stock market data...")
    current_date = datetime.now().strftime('%B %d, %Y')
    system_message = SystemMessage(content=f"""
You are an expert Stock Market Analyst and Investment Advisor. 

Based on the following LIVE market data and context: {context}

Provide a comprehensive stock analysis for the question: {question}

Your response should include:
1. **Current Market Data**: TODAY'S ({current_date}) latest prices, closing prices, changes, volume if available. If today's data isn't available, use the MOST RECENT closing price and specify the date.
2. **Financial Analysis**: Key metrics like P/E ratio, market cap, revenue trends
3. **Based on Recent News**: Analyze the MOST RECENT news and events affecting this stock. Explain how recent developments, earnings reports, product launches, partnerships, regulatory changes, or market sentiment are impacting the stock's performance. Focus on news from the last few days/weeks.
4. **Technical Analysis**: Price trends, support/resistance levels if relevant  
5. **Investment Recommendation**: BUY/HOLD/SELL with clear reasoning
6. **Risk Assessment**: Potential risks and opportunities
7. **Price Targets**: Short-term and long-term projections if possible
8. **Sources**: Include all source links at the end for verification

Use LIVE, UP-TO-DATE information from the provided context. Be specific with numbers, dates, and sources.
Prioritize getting TODAY'S closing price or the most recent available closing price.
Format your response clearly with headers and bullet points for easy reading.

IMPORTANT: At the end of your response, include only some best 6 "📚 Sources:" section with all the URLs and links from the provided context so users can verify the information and read more details.
""")
    messages = messages+[system_message]
    
    # Stream the response
    print("\n📊 Stock Analyst: ", end="", flush=True)
    for chunk in llm.stream([
        system_message,
        HumanMessage(content="Provide comprehensive stock analysis and recommendations.")
    ]):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            full_response += chunk.content
    print()  # New line after streaming
    
  else:
    print("💬 Using previous stock discussion...")
    # Add stock context to conversation-based responses
    stock_context_message = SystemMessage(content="""
You are a Stock Market Expert. When answering questions about previous conversations, 
maintain your role as a financial advisor. Keep responses focused on stock market topics,
investment advice, and financial analysis. Be helpful and professional.
""")
    human_message = HumanMessage(content=question)
    messages = [stock_context_message] + messages + [human_message]
    
    # Stream the response
    print("\n📊 Stock Analyst: ", end="", flush=True)
    for chunk in llm.stream(messages):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            full_response += chunk.content
    print()  # New line after streaming

  return {
        "answer": full_response,  # get the full streamed response
        "messages": messages + [AIMessage(content=full_response)]
    }

def route_based_on_search(state) -> str:
    if state.get("needs_search"):
        return "search_web"
    else:
        return "generate_answer"

from langgraph.graph import  StateGraph,START,END
from langgraph.graph import  MessagesState
from langgraph.prebuilt import  ToolNode
from langgraph.prebuilt import  tools_condition
# from IPython.display import Image,display
from langchain_core.messages import HumanMessage ,SystemMessage
from langgraph.checkpoint.memory import MemorySaver


memory=MemorySaver()


builder = StateGraph(Researchstate)

builder.add_node("check",check)

# Initialize each node with node_secret
builder.add_node("search_web",search_web)
builder.add_node("search_wikipedia", search_wiki)
builder.add_node("generate_answer", generate_ans)

# Flow
builder.add_edge(START, "check")
builder.add_conditional_edges(
    "check",                    # the current node name
    route_based_on_search,      # your routing function
    ["search_web", "generate_answer"]  # possible destinations
)
builder.add_edge("search_web", "search_wikipedia")
builder.add_edge("search_wikipedia", "generate_answer")
builder.add_edge("generate_answer", END)
graph = builder.compile(checkpointer=memory)

# display(Image(graph.get_graph().draw_mermaid_png()))

def main():
    """Main interactive function to get user input and process stock questions"""
    config = {"configurable": {"thread_id": "stock_session"}}
    
    print("📈 Welcome to the Live Stock Market Research Assistant!")
    print("🔴 LIVE MARKET DATA | 📊 EXPERT ANALYSIS | 💡 INVESTMENT RECOMMENDATIONS")
    print("Ask me about any stock, market trends, or investment advice.")
    print("Type 'quit', 'exit', or 'bye' to end the session.\n")
    print("🔥 Try asking:")
    print("   • 'What's the current price of AAPL stock?'")
    print("   • 'Should I buy Tesla stock now?'")
    print("   • 'Compare NVIDIA vs AMD stocks'")
    print("   • 'What are the best tech stocks to buy?'\n")
    
    while True:
        try:
            # Get user input
            user_question = input("📈 Your stock question: ").strip()
            
            # Check for exit commands
            if user_question.lower() in ['quit', 'exit', 'bye', 'q']:
                print("💰 Happy Trading! Thanks for using the Stock Research Assistant!")
                break
            
            # Skip empty questions
            if not user_question:
                print("Please enter a stock market question.")
                continue
            
            print(f"\n🔍 Analyzing: '{user_question}'")
            print("-" * 60)
            
            # Process the question through the graph
            result = graph.invoke({"question": user_question}, config=config)
            
            # The streaming already happened in generate_ans, so we just need to show completion
            print(f"\n✅ Analysis completed!")
            print("💡 Remember: This is not financial advice. Always do your own research!")
            print("\n" + "="*80 + "\n")
            
        except KeyboardInterrupt:
            print("\n\n💰 Session interrupted. Happy Trading!")
            break
        except Exception as e:
            print(f"❌ An error occurred: {e}")
            print("Please try again with a different stock question.\n")

if __name__ == "__main__":
    main()

